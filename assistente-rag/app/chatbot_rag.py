# SPDX-License-Identifier: PolyForm-Noncommercial-1.0.0
# Copyright (c) 2026 Lenon de Paula - https://github.com/lenondpaula
"""
Chatbot RAG - Assistente Corporativo
Interface Streamlit para perguntas sobre documentos PDF
Usa busca semÃ¢ntica (ChromaDB) + geraÃ§Ã£o de respostas com Gemini API
"""

from pathlib import Path
import sys
import shutil

import streamlit as st

# Adiciona src ao path para imports
BASE_DIR = Path(__file__).resolve().parents[1]
PROJECT_ROOT = BASE_DIR.parent
SRC_DIR = BASE_DIR / "src"
DB_DIR = BASE_DIR / "db_store"
sys.path.insert(0, str(SRC_DIR))
sys.path.insert(0, str(PROJECT_ROOT))

from processador_pdf import processar_pdf_upload
from indexador import (
    criar_ou_carregar_vectorstore,
    indexar_documentos,
    buscar_com_scores,
    contar_documentos,
)
from shared.components import (  # noqa: E402
    SHARED_SIDEBAR_CSS,
    render_sidebar_header,
    render_sidebar_footer,
    render_rodape,
    render_instrucoes_uso,
)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# CONFIGURAÃ‡Ã•ES
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
MAX_FILE_SIZE_MB = 100  # Limite de 100MB por arquivo
GEMINI_MODEL_DEFAULT = "gemini-1.5-flash"  # Modelo rÃ¡pido e eficiente do Google
GEMINI_API_KEY = "AIzaSyC6pihdReWGrWDB19LHqQSc-cHGtm9a0X8"  # API Key do Gemini


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# CSS corporativo minimalista (padrÃ£o do Hub)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
CUSTOM_CSS = """
<style>
:root {
    --primary: #0f172a;
    --secondary: #334155;
    --accent: #3b82f6;
    --success: #22c55e;
    --danger: #ef4444;
    --warning: #f59e0b;
    --bg: #f8fafc;
}
html, body, [class*="css"] {
    font-family: 'Inter', 'Segoe UI', sans-serif;
}
.block-container {
    padding-top: 2rem;
    max-width: 1000px;
}
h1 {
    color: var(--primary);
    font-weight: 700;
    letter-spacing: -0.5px;
}
section[data-testid="stSidebar"] {
    background: var(--primary);
}
section[data-testid="stSidebar"] h1,
section[data-testid="stSidebar"] h2,
section[data-testid="stSidebar"] h3,
section[data-testid="stSidebar"] p,
section[data-testid="stSidebar"] span,
section[data-testid="stSidebar"] label {
    color: #e2e8f0 !important;
    font-weight: 500;
}
/* File uploader - fundo escuro com texto claro */
section[data-testid="stSidebar"] [data-testid="stFileUploader"] {
    background: #1e293b;
    border: 2px dashed #475569;
    border-radius: 8px;
    padding: 1rem;
}
section[data-testid="stSidebar"] [data-testid="stFileUploader"] * {
    color: #e2e8f0 !important;
}
/* BotÃµes na sidebar */
section[data-testid="stSidebar"] button {
    background: #3b82f6 !important;
    color: #ffffff !important;
    border: none !important;
    font-weight: 600 !important;
}
section[data-testid="stSidebar"] button:hover {
    background: #2563eb !important;
}
.chat-message {
    padding: 1rem;
    border-radius: 12px;
    margin-bottom: 0.75rem;
}
.chat-user {
    background: #dbeafe;
    border: 1px solid #93c5fd;
}
.chat-assistant {
    background: #f1f5f9;
    border: 1px solid #e2e8f0;
}
.fonte-card {
    background: #ffffff;
    border: 1px solid #e2e8f0;
    border-radius: 8px;
    padding: 0.75rem;
    margin-bottom: 0.5rem;
    font-size: 0.85rem;
}
.fonte-header {
    font-weight: 600;
    color: var(--primary);
    margin-bottom: 0.25rem;
}
.fonte-trecho {
    color: var(--secondary);
    font-size: 0.8rem;
}
.status-card {
    border-radius: 12px;
    padding: 1rem 1.5rem;
    text-align: center;
    font-size: 1rem;
    font-weight: 700;
    margin: 0.5rem 0;
}
.status-ok {
    background: #065f46 !important;
    color: #ffffff !important;
    border: 1px solid #34d399;
}
.status-warning {
    background: #92400e !important;
    color: #ffffff !important;
    border: 1px solid #fbbf24;
}
.status-danger {
    background: #991b1b !important;
    color: #ffffff !important;
    border: 1px solid #f87171;
}
.groq-status {
    padding: 0.5rem;
    border-radius: 8px;
    font-size: 0.85rem;
    font-weight: 700;
    text-align: center;
    margin: 0.5rem 0;
}
.groq-online {
    background: #166534 !important;
    color: #ffffff !important;
}
.groq-offline {
    background: #991b1b !important;
    color: #ffffff !important;
}
/* BotÃ£o de limpeza (vermelho) */
.btn-danger {
    background: #dc2626 !important;
    border: 1px solid #b91c1c !important;
}
.btn-danger:hover {
    background: #b91c1c !important;
}
</style>
"""


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# FUNÃ‡Ã•ES GEMINI API
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def obter_gemini_api_key() -> str:
    """ObtÃ©m API key do Gemini de constante, secrets ou variÃ¡vel de ambiente."""
    import os
    
    # Primeiro tenta usar a constante definida
    if GEMINI_API_KEY and GEMINI_API_KEY.strip():
        return GEMINI_API_KEY
    
    # Tenta obter de secrets do Streamlit
    try:
        if hasattr(st, 'secrets') and 'GEMINI_API_KEY' in st.secrets:
            return st.secrets['GEMINI_API_KEY']
    except Exception:
        pass
    
    # Fallback para variÃ¡vel de ambiente
    return os.getenv('GEMINI_API_KEY', '')


def verificar_gemini() -> bool:
    """Verifica se a API do Gemini estÃ¡ configurada."""
    api_key = obter_gemini_api_key()
    return bool(api_key and api_key.strip())


def gerar_resposta_gemini(pergunta: str, contextos: list, modelo: str = GEMINI_MODEL_DEFAULT) -> str:
    """Gera resposta usando Gemini API."""
    try:
        from langchain_google_genai import ChatGoogleGenerativeAI
        
        api_key = obter_gemini_api_key()
        if not api_key:
            return "âŒ Chave API do Gemini nÃ£o configurada."
        
        # Monta o contexto
        contexto_texto = "\n\n".join([
            f"Trecho {i+1} (de {doc.metadata.get('fonte', 'documento')}):\n{doc.page_content}"
            for i, (doc, score) in enumerate(contextos)
        ])
        
        # Prompt otimizado para RAG
        prompt = f"""VocÃª Ã© um assistente corporativo inteligente. Use APENAS as informaÃ§Ãµes do contexto abaixo para responder Ã  pergunta. Se a informaÃ§Ã£o nÃ£o estiver no contexto, diga que nÃ£o encontrou a informaÃ§Ã£o nos documentos.

CONTEXTO:
{contexto_texto}

PERGUNTA: {pergunta}

RESPOSTA (seja conciso e objetivo):"""

        llm = ChatGoogleGenerativeAI(
            model=modelo,
            google_api_key=api_key,
            temperature=0.3,
            max_output_tokens=1024,
        )
        
        resposta = llm.invoke(prompt)
        return resposta.content.strip()
        
    except Exception as e:
        return f"âŒ Erro ao gerar resposta: {str(e)}"


def gerar_resposta_sem_llm(pergunta: str, contextos: list) -> str:
    """Fallback quando Gemini nÃ£o estÃ¡ disponÃ­vel."""
    if not contextos:
        return "NÃ£o encontrei informaÃ§Ãµes relevantes nos documentos para responder sua pergunta."
    
    resposta = "ğŸ“š **Trechos relevantes encontrados:**\n\n"
    
    for i, (doc, score) in enumerate(contextos, 1):
        trecho = doc.page_content.strip()
        fonte = doc.metadata.get("fonte", "Documento")
        resposta += f"**Trecho {i}** (de *{fonte}*):\n"
        resposta += f"> {trecho}\n\n"
    
    resposta += "---\n"
    resposta += "*â„¹ï¸ Configure a API do Gemini para respostas elaboradas por IA.*"
    
    return resposta


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# FUNÃ‡Ã•ES DE GERENCIAMENTO
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def limpar_base_documentos():
    """Remove todos os documentos indexados."""
    try:
        if DB_DIR.exists():
            shutil.rmtree(DB_DIR)
            st.session_state.vectorstore = None
            return True
    except Exception as e:
        st.error(f"Erro ao limpar base: {str(e)}")
    return False


def inicializar_sessao():
    """Inicializa variÃ¡veis de sessÃ£o do Streamlit."""
    if "mensagens" not in st.session_state:
        st.session_state.mensagens = []
    if "vectorstore" not in st.session_state:
        st.session_state.vectorstore = None
    if "fontes_ultima_resposta" not in st.session_state:
        st.session_state.fontes_ultima_resposta = []


def carregar_vectorstore():
    """Carrega ou cria a base vetorial."""
    if st.session_state.vectorstore is None:
        with st.spinner("ğŸ”® Carregando base de conhecimento..."):
            st.session_state.vectorstore = criar_ou_carregar_vectorstore()
    return st.session_state.vectorstore


def processar_upload(arquivo_pdf):
    """Processa PDF enviado pelo usuÃ¡rio."""
    if arquivo_pdf is None:
        return
    
    # Verifica tamanho do arquivo
    file_size_mb = len(arquivo_pdf.getvalue()) / (1024 * 1024)
    if file_size_mb > MAX_FILE_SIZE_MB:
        st.error(f"âŒ Arquivo muito grande ({file_size_mb:.1f}MB). MÃ¡ximo: {MAX_FILE_SIZE_MB}MB")
        return
    
    with st.spinner(f"ğŸ“„ Processando {arquivo_pdf.name}..."):
        chunks = processar_pdf_upload(arquivo_pdf.getvalue(), arquivo_pdf.name)
        
        if not chunks:
            st.error("âŒ NÃ£o foi possÃ­vel extrair texto do PDF.")
            return
        
        st.session_state.vectorstore = indexar_documentos(chunks, limpar_base=False)
        st.success(f"âœ… {len(chunks)} trechos indexados de '{arquivo_pdf.name}'!")


def processar_pergunta(pergunta: str):
    """Processa pergunta do usuÃ¡rio e gera resposta."""
    vectorstore = carregar_vectorstore()
    
    num_docs = contar_documentos(vectorstore)
    if num_docs == 0:
        return "âš ï¸ Nenhum documento indexado. FaÃ§a upload de um PDF primeiro!", []
    
    with st.spinner("ğŸ” Buscando informaÃ§Ãµes relevantes..."):
        resultados = buscar_com_scores(pergunta, k=3, vectorstore=vectorstore)
    
    if not resultados:
        return "NÃ£o encontrei informaÃ§Ãµes relevantes para sua pergunta.", []
    
    # Usa Gemini se disponÃ­vel, senÃ£o mostra chunks
    if verificar_gemini():
        with st.spinner(f"âš¡ Gerando resposta com Gemini..."):
            resposta = gerar_resposta_gemini(pergunta, resultados, GEMINI_MODEL_DEFAULT)
    else:
        resposta = gerar_resposta_sem_llm(pergunta, resultados)
    
    return resposta, resultados


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# RENDERIZAÃ‡ÃƒO
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def render_chat():
    """Renderiza histÃ³rico de chat."""
    for msg in st.session_state.mensagens:
        if msg["role"] == "user":
            st.markdown(
                f'<div class="chat-message chat-user">ğŸ‘¤ <strong>VocÃª:</strong> {msg["content"]}</div>',
                unsafe_allow_html=True
            )
        else:
            st.markdown(
                f'<div class="chat-message chat-assistant">ğŸ¤– <strong>Assistente:</strong><br>{msg["content"]}</div>',
                unsafe_allow_html=True
            )


def render_fontes(fontes: list):
    """Renderiza as fontes usadas na Ãºltima resposta."""
    if not fontes:
        st.caption("Nenhuma fonte disponÃ­vel")
        return
    
    for i, (doc, score) in enumerate(fontes, 1):
        fonte = doc.metadata.get("fonte", "N/A")
        pagina = doc.metadata.get("page", "N/A")
        trecho = doc.page_content[:150] + "..." if len(doc.page_content) > 150 else doc.page_content
        similaridade = max(0, min(100, int((1 - score) * 100)))
        
        st.markdown(
            f"""
            <div class="fonte-card">
                <div class="fonte-header">ğŸ“„ {fonte} (pÃ¡g. {pagina})</div>
                <div class="fonte-trecho">{trecho}</div>
                <div style="margin-top:0.5rem;">
                    <span style="background:#dbeafe; color:#1e40af; padding:0.15rem 0.5rem; border-radius:8px; font-size:0.7rem;">
                        RelevÃ¢ncia: {similaridade}%
                    </span>
                </div>
            </div>
            """,
            unsafe_allow_html=True
        )


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# APP PRINCIPAL
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def render_app():
    """FunÃ§Ã£o principal do chatbot."""
    
    st.markdown(CUSTOM_CSS, unsafe_allow_html=True)
    st.markdown(SHARED_SIDEBAR_CSS, unsafe_allow_html=True)
    inicializar_sessao()
    
    st.title("ğŸ¤– Assistente Corporativo")
    st.markdown("FaÃ§a perguntas sobre seus documentos PDF usando **RAG** (Retrieval-Augmented Generation)")
    
    # InstruÃ§Ãµes de uso
    render_instrucoes_uso(
        instrucoes=[
            "FaÃ§a upload de PDFs na sidebar (mÃ¡x. 100MB)",
            "Aguarde a indexaÃ§Ã£o dos documentos",
            "Digite sua pergunta no chat",
        ],
        ferramentas_sidebar=[
            "**ğŸ“¤ Upload PDF** â€“ Envie documentos para indexar",
            "**ğŸ“Š Status** â€“ Quantidade de docs indexados",
            "**âš¡ Modelo** â€“ Gemini API (gemini-1.5-flash)",
            "**ğŸ—‘ï¸ Limpar** â€“ Remove documentos ou conversa",
        ]
    )
    
    with st.container():
        st.markdown(
            """
            <div style="background:#f1f5f9; border-left:4px solid #8b5cf6; padding:1rem 1.25rem; border-radius:6px; margin-bottom:1.5rem;">
                <strong>O que Ã© RAG?</strong><br>
                <em>Retrieval-Augmented Generation</em> combina busca semÃ¢ntica com IA generativa.
                O sistema encontra trechos relevantes nos seus documentos e usa como contexto para responder.<br><br>
                <strong>Como usar</strong><br>
                1. FaÃ§a upload de um PDF na barra lateral<br>
                2. Aguarde a indexaÃ§Ã£o<br>
                3. FaÃ§a perguntas sobre o conteÃºdo!
            </div>
            """,
            unsafe_allow_html=True,
        )
    
    # â”€â”€ Sidebar Header (Home + Menu AplicaÃ§Ãµes) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    render_sidebar_header()

    # â”€â”€ ConteÃºdo especÃ­fico do app na sidebar â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    with st.sidebar:
        st.markdown("### ğŸ“ Documentos")
        
        arquivo_pdf = st.file_uploader(
            "Upload PDF (mÃ¡x. 100MB)",
            type=["pdf"],
            help=f"Tamanho mÃ¡ximo: {MAX_FILE_SIZE_MB}MB"
        )
        
        if arquivo_pdf:
            file_size_mb = len(arquivo_pdf.getvalue()) / (1024 * 1024)
            st.caption(f"ğŸ“„ {arquivo_pdf.name} ({file_size_mb:.1f}MB)")
            
            if st.button("ğŸ“¤ Indexar documento", use_container_width=True):
                processar_upload(arquivo_pdf)
        
        st.markdown("---")
        
        # Status da base
        st.markdown("### ğŸ“Š Status da Base")
        vectorstore = carregar_vectorstore()
        num_docs = contar_documentos(vectorstore)
        
        st.metric("Documentos indexados", num_docs)
        
        if num_docs > 0:
            st.markdown('<div class="status-card status-ok">âœ… Pronto para perguntas</div>', unsafe_allow_html=True)
        else:
            st.markdown('<div class="status-card status-warning">âš ï¸ Base vazia</div>', unsafe_allow_html=True)
        
        st.markdown("---")
        
        # Status do Gemini
        st.markdown("### âš¡ Modelo de IA")
        gemini_disponivel = verificar_gemini()
        
        if gemini_disponivel:
            st.markdown('<div class="gemini-status gemini-online">âœ… Gemini API Conectada</div>', unsafe_allow_html=True)
            st.caption(f"Modelo: `{GEMINI_MODEL_DEFAULT}`")
        else:
            st.markdown('<div class="gemini-status gemini-offline">âŒ Gemini nÃ£o configurado</div>', unsafe_allow_html=True)
            st.info(
                """
                Para respostas por IA:
                1. Acesse [Google AI Studio](https://aistudio.google.com/app/apikey)
                2. Gere uma API key
                3. Adicione ao `.streamlit/secrets.toml`:
                ```toml
                GEMINI_API_KEY = "sua_chave"
                ```
                """
            )
        
        st.markdown("---")
        
        # Fontes da Ãºltima resposta
        st.markdown("### ğŸ“š Fontes Utilizadas")
        render_fontes(st.session_state.fontes_ultima_resposta)
        
        st.markdown("---")
        
        # AÃ§Ãµes de limpeza
        st.markdown("### ğŸ—‘ï¸ Gerenciamento")
        
        col1, col2 = st.columns(2)
        
        with col1:
            if st.button("ğŸ’¬ Limpar Chat", use_container_width=True, help="Limpa histÃ³rico de conversa"):
                st.session_state.mensagens = []
                st.session_state.fontes_ultima_resposta = []
                st.rerun()
        
        with col2:
            if num_docs > 0:
                if st.button("ğŸ“ Limpar Base", use_container_width=True, help="Remove todos os documentos indexados"):
                    if limpar_base_documentos():
                        st.success("âœ… Base limpa!")
                        st.rerun()

    # â”€â”€ Sidebar Footer (Contato + Copyright) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    render_sidebar_footer()
    
    # â”€â”€ Chat â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    st.markdown("---")
    render_chat()
    
    pergunta = st.chat_input("Digite sua pergunta sobre os documentos...")
    
    if pergunta:
        st.session_state.mensagens.append({"role": "user", "content": pergunta})
        
        resposta, fontes = processar_pergunta(pergunta)
        
        st.session_state.mensagens.append({"role": "assistant", "content": resposta})
        st.session_state.fontes_ultima_resposta = fontes
        st.rerun()

    # Footer
    render_rodape(
        titulo_app="ğŸ¤– Assistente Corporativo RAG",
        subtitulo="Perguntas e respostas sobre documentos com busca semÃ¢ntica",
        tecnologias="LangChain + ChromaDB + HuggingFace + Gemini"
    )


if __name__ == "__main__":
    st.set_page_config(
        page_title="Assistente Corporativo RAG",
        page_icon="ğŸ¤–",
        layout="wide",
        initial_sidebar_state="expanded",
    )
    render_app()
