# Copilot Instructions - Hub de Cria√ß√£o

## Vis√£o Geral da Arquitetura

Este √© um **portfolio multi-aplica√ß√£o** com Streamlit que hospeda 3+ apps de ML/NLP independentes em um √∫nico projeto. O arquivo [streamlit_app.py](../streamlit_app.py) serve como **homepage-√≠ndice**, enquanto cada app reside em `pages/` ou como subm√≥dulo pr√≥prio.

### Estrutura de Apps
- **App 1 (Previs√£o de Falhas)**: Manuten√ß√£o preditiva com RandomForest ‚Üí [pages/1_Previsao_Falhas.py](../pages/1_Previsao_Falhas.py)
- **App 2 (An√°lise de Sentimentos)**: NLP com TextBlob ‚Üí [pages/2_Analise_Sentimentos.py](../pages/2_Analise_Sentimentos.py), m√≥dulo completo em [analise-sentimentos/](../analise-sentimentos/)
- **App 3 (Recomenda√ß√£o)**: SVD com Surprise ‚Üí [pages/3_Que_tal_esse.py](../pages/3_Que_tal_esse.py), m√≥dulo em [sistema-recomendacao/](../sistema-recomendacao/)

## Conven√ß√µes do Projeto

### Estrutura de M√≥dulos Independentes
Cada app segue o padr√£o:
```
<nome-app>/
‚îú‚îÄ‚îÄ app/          # Dashboard principal (ex: dashboard.py, loja.py)
‚îú‚îÄ‚îÄ data/         # CSVs gerados/processados
‚îú‚îÄ‚îÄ src/          # L√≥gica de neg√≥cio (gera√ß√£o de dados, treino)
‚îú‚îÄ‚îÄ models/       # Modelos .pkl treinados
‚îî‚îÄ‚îÄ requirements.txt
```

### Sistema de Paths
**CR√çTICO**: Use `Path(__file__).resolve().parents[N]` para navega√ß√£o:
- Apps em `pages/`: `parents[1]` para raiz, `parents[1] / "sistema-recomendacao"` para subm√≥dulos
- Apps em subm√≥dulos: `parents[1]` j√° est√° na raiz do subm√≥dulo
- Exemplo: [pages/3_Que_tal_esse.py#L9](../pages/3_Que_tal_esse.py#L9) importa de `sistema-recomendacao/app/`

### CSS Corporativo Consistente
Todos os apps compartilham o mesmo tema minimalista:
```python
CUSTOM_CSS = """<style>
:root {
    --primary: #0f172a;
    --accent: #3b82f6;
    --success: #22c55e;
    --danger: #ef4444;
}
"""
```
Ver [streamlit_app.py#L18-L100](../streamlit_app.py#L18-L100) para template completo.

## Workflows de Desenvolvimento

### 1. Treinar Modelo de Previs√£o de Falhas
```bash
python gerar_dados.py              # Gera data/raw/sensor_data.csv
python src/train_model.py          # Treina e salva models/modelo_preditivo.pkl
streamlit run pages/1_Previsao_Falhas.py
```

### 2. Setup An√°lise de Sentimentos
```bash
cd analise-sentimentos
python setup_nltk.py               # Download de recursos NLTK
python src/gerador_dados.py        # Gera dados sint√©ticos
python src/analise_motor.py        # Analisa sentimentos
# Execu√ß√£o via p√°gina do hub: streamlit run streamlit_app.py
```

### 3. Treinar Sistema de Recomenda√ß√£o
```bash
cd sistema-recomendacao
python src/gerar_dataset.py        # Cria produtos.csv e avaliacoes.csv
python src/treinar_modelo.py       # Treina SVD e salva models/recommender.pkl
```

### 4. Executar Hub Completo
```bash
streamlit run streamlit_app.py     # Homepage em http://localhost:8501
```

## Detalhes T√©cnicos Importantes

### Gera√ß√£o de Dados Sint√©ticos
Todos os apps usam **dados simulados** com Faker/NumPy para demonstra√ß√£o:
- **Sensores industriais**: [gerar_dados.py](../gerar_dados.py) - balanceamento de classes 30/70
- **Coment√°rios sociais**: [analise-sentimentos/src/gerador_dados.py](../analise-sentimentos/src/gerador_dados.py)
- **Avalia√ß√µes e-commerce**: [sistema-recomendacao/src/gerar_dataset.py](../sistema-recomendacao/src/gerar_dataset.py)

### Cache de Recursos
Use decoradores Streamlit para performance:
```python
@st.cache_data(show_spinner=False)  # Para DataFrames
def carregar_dados(): ...

@st.cache_resource(show_spinner=False)  # Para modelos
def carregar_modelo(): ...
```

### Integra√ß√£o NLTK
TextBlob requer downloads pr√©vios - sempre inclua fallback:
```python
import nltk
try:
    nltk.data.find('tokenizers/punkt')
except LookupError:
    nltk.download('punkt', quiet=True)
```

### Constraints de Depend√™ncias
- `numpy<2.0` e `cython<3.0` por compatibilidade com scikit-surprise
- Ver [requirements.txt](../requirements.txt) na raiz para vers√µes espec√≠ficas

## Padr√µes de C√≥digo

### Imports de Subm√≥dulos
```python
# Em pages/X.py, para importar de subm√≥dulo:
APP_DIR = Path(__file__).resolve().parents[1] / "sistema-recomendacao" / "app"
sys.path.insert(0, str(APP_DIR))
from loja import render_app  # noqa: E402
```

### Modelos Scikit-learn
- Salvos com `joblib.dump()` em `models/`
- RandomForest com `class_weight="balanced"` para classes desbalanceadas
- Sempre imprima F1-score, n√£o apenas acur√°cia

### Dashboard KPIs
Layout em cards HTML customizados com gradientes CSS:
```python
st.markdown(f'<div class="status-ok">‚úÖ Sistema Saud√°vel</div>', unsafe_allow_html=True)
```

## Detalhes dos Apps 4 e 5

### App 4: O Or√°culo de Vendas (BI Preditivo com Prophet)

**Estrutura**:
```
oraculo-vendas/
‚îú‚îÄ‚îÄ app/
‚îÇ   ‚îî‚îÄ‚îÄ dashboard_vendas.py      # Dashboard principal com KPIs
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îî‚îÄ‚îÄ vendas_historico.csv     # 3 anos de hist√≥rico sint√©tico (1096 dias)
‚îú‚îÄ‚îÄ models/
‚îÇ   ‚îî‚îÄ‚îÄ prophet_model.pkl         # Modelo Prophet treinado
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ gerar_vendas.py          # Gera√ß√£o de dados com tend√™ncia + sazonalidade
‚îÇ   ‚îî‚îÄ‚îÄ treinar_oraculo.py       # Treino do modelo Prophet
‚îî‚îÄ‚îÄ requirements.txt
```

**Workflow de Treino**:
```bash
cd oraculo-vendas
python src/gerar_vendas.py              # Gera data/vendas_historico.csv
python src/treinar_oraculo.py           # Treina e salva models/prophet_model.pkl
streamlit run ../pages/4_O_Oraculo_de_Vendas.py
```

**Caracter√≠sticas T√©cnicas**:
- **Dados sint√©ticos**: 3 anos de vendas di√°rias com padr√µes realistas:
  - Tend√™ncia linear (crescimento suave)
  - Sazonalidade multiplicativa (7 dias, 365 dias)
  - Pico de Black Friday (~40% acima da m√©dia)
  - Ru√≠do gaussiano (¬±5%)
- **Configura√ß√£o Prophet**:
  - `interval_width=0.95` para intervalos de confian√ßa (IC 95%)
  - Multiplicative seasonality (mais realista para dados de vendas)
  - Feriados brasileiros registrados (e.g., Black Friday em Nov)
  - `yearly_seasonality=True`, `weekly_seasonality=True`, `daily_seasonality=False`
- **Dashboard**:
  - KPIs: Pr√≥ximo m√™s estimado, varia√ß√£o vs hist√≥rico, confiabilidade IC
  - Gr√°ficos Plotly: S√©rie hist√≥rica + forecast, decomposi√ß√£o de componentes, res√≠duos
  - Export: CSV com forecast (com IC inferior/superior) e par√¢metros do modelo
  - Slider para ajustar per√≠odos de forecast (7 a 90 dias)

**Imports Cr√≠ticos**:
```python
from prophet import Prophet
from pathlib import Path
import joblib
import plotly.graph_objects as go
```

**Checklist de Deploy**:
- [ ] Dados gerados com seed=42 para reproducibilidade
- [ ] Modelo pickleado em `models/prophet_model.pkl`
- [ ] CSS corporativo aplicado no dashboard
- [ ] Cache Streamlit para dados (`@st.cache_data`)
- [ ] Conversor de forecast DataFrame para CSV

---

### App 5: O Assistente Corporativo (RAG com Ollama)

**Estrutura**:
```
assistente-rag/
‚îú‚îÄ‚îÄ app/
‚îÇ   ‚îî‚îÄ‚îÄ chatbot_rag.py               # Interface RAG + Ollama
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îî‚îÄ‚îÄ (PDFs do usu√°rio)
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ processador_pdf.py           # Extra√ß√£o de texto com PyPDF
‚îÇ   ‚îî‚îÄ‚îÄ indexador.py                 # Indexa√ß√£o ChromaDB
‚îú‚îÄ‚îÄ models/
‚îÇ   ‚îî‚îÄ‚îÄ (ChromaDB vectors)
‚îî‚îÄ‚îÄ requirements.txt
```

**Workflow de Setup**:
```bash
cd assistente-rag
# Local: Instalar Ollama manualmente (https://ollama.ai)
ollama pull llama3.2                 # ~2.3GB

# Streamlit Cloud: Autom√°tico via detectar_streamlit_cloud()
streamlit run ../pages/5_O_Assistente_Corporativo.py
```

**Arquitetura RAG**:
1. **Ingest√£o (PDF)**:
   - PyPDF2 extrai texto bruto de PDFs
   - RecursiveCharacterTextSplitter divide em chunks (600 chars, 200 overlap)
   - Embedding: sentence-transformers/all-MiniLM-L6-v2 (384-dim, CPU)

2. **Indexa√ß√£o (ChromaDB)**:
   - Vector store em disco (`chroma_vectordb/`)
   - Similaridade cosine para recupera√ß√£o
   - Scoring autom√°tico per chunk (0-1)

3. **Gera√ß√£o (Ollama LLM)**:
   - Endpoint local: `http://localhost:11434`
   - Modelo default: `llama3.2` (Ollama auto-seleciona)
   - Context window: at√© 2048 tokens
   - Temperature: 0.7 (balanceado)

**Fun√ß√µes Principais** (em `chatbot_rag.py`):
```python
def detectar_streamlit_cloud() -> bool:
    """Detecta se est√° rodando em Streamlit Cloud"""
    return os.getenv("STREAMLIT_SERVER_HEADLESS") == "true"

def verificar_ollama() -> bool:
    """Verifica se Ollama est√° instalado e rodando"""
    # shutil.which("ollama") + HTTP health check em :11434

def listar_modelos_ollama() -> list[str]:
    """List: GET /api/tags"""

def instalar_ollama_cloud() -> bool:
    """subprocess + apt para Cloud (detecta ubuntu/debian)"""

def gerar_resposta_ollama(prompt: str, contexto: str) -> str:
    """LLM inference com contexto do RAG"""
```

**Imports Cr√≠ticos** (v0.3+ LangChain):
```python
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_core.documents import Document
from langchain_community.vectorstores import Chroma
from langchain_community.embeddings import HuggingFaceEmbeddings
from langchain_ollama import ChatOllama
```

**Comportamento Offline**:
- Ollama offline ‚Üí Mostra chunks relevantes do PDF (fallback gracioso)
- Interrup√ß√£o de conex√£o ‚Üí Tenta reconectar, depois fallback
- Streamlit Cloud sem Docker ‚Üí Oferece bot√£o "üì• Instalar Ollama"

**Checklist de Deploy**:
- [ ] ChromaDB persiste em `chroma_vectordb/` na raiz do subm√≥dulo
- [ ] Ollama health check em `/proc/pid` ou HTTP
- [ ] Environment detection para Streamlit Cloud
- [ ] Auto-install subprocess com quoting seguro
- [ ] Cache Streamlit para embeddings (`@st.cache_resource`)
- [ ] Tratamento de PDFs inv√°lidos/vazio
- [ ] Sidebar com upload + hist√≥rico de chat

**Notas para Streamlit Cloud**:
- Ollama requer Docker ou sistema Unix (WSL em Windows)
- Instala√ß√£o via apt-get em primeiro boot (~5-10 min)
- Modelo `llama3.2` baixa ~2.3GB (cache via `/root/.ollama`)
- Recursos: ~2GB RAM + 500MB CPU suficientes para llama3.2

## Como Adicionar um Novo App ao Hub

### Op√ß√£o 1: App Simples (Tudo em `pages/`)
Para apps autocontidos sem m√≥dulos complexos:

1. **Criar p√°gina em `pages/`**:
   ```python
   # pages/4_Novo_App.py
   from pathlib import Path
   import streamlit as st
   
   MODEL_PATH = Path(__file__).resolve().parents[1] / "models" / "novo_modelo.pkl"
   DATA_PATH = Path(__file__).resolve().parents[1] / "data" / "novo_dataset.csv"
   ```

2. **Adicionar CSS padr√£o**: Copie o bloco `CUSTOM_CSS` de [pages/1_Previsao_Falhas.py#L12-L74](../pages/1_Previsao_Falhas.py#L12-L74)

3. **Registrar no hub**: Adicione entrada em `streamlit_app.py`:
   ```python
   APPS = [
       # ... apps existentes ...
       {
           "title": "üìà App 4 ‚Äî Novo App",
           "desc": "Descri√ß√£o concisa do que o app faz.",
           "status": "active",  # ou "dev"
           "page": "pages/4_Novo_App",
       },
   ]
   ```

### Op√ß√£o 2: App Modular (Com Subm√≥dulo)
Para apps com l√≥gica complexa ou m√∫ltiplos arquivos:

1. **Criar estrutura de subm√≥dulo**:
   ```bash
   mkdir -p novo-app/{app,data,models,src}
   touch novo-app/requirements.txt
   ```

2. **Implementar l√≥gica no subm√≥dulo**:
   ```python
   # novo-app/app/dashboard.py
   from pathlib import Path
   
   BASE_DIR = Path(__file__).resolve().parents[1]
   
   def render_app():
       st.title("Novo App")
       # L√≥gica do dashboard aqui
   ```

3. **Criar p√°gina ponte em `pages/`**:
   ```python
   # pages/4_Novo_App.py
   from pathlib import Path
   import sys
   import streamlit as st
   
   APP_DIR = Path(__file__).resolve().parents[1] / "novo-app" / "app"
   sys.path.insert(0, str(APP_DIR))
   from dashboard import render_app  # noqa: E402
   
   st.set_page_config(page_title="Novo App", page_icon="üìà", layout="wide")
   render_app()
   ```

4. **Adicionar scripts auxiliares**:
   - `novo-app/src/gerar_dados.py` - Gera√ß√£o de dados sint√©ticos
   - `novo-app/src/treinar_modelo.py` - Treino de modelos
   - `novo-app/requirements.txt` - Depend√™ncias espec√≠ficas

5. **Registrar no hub** (mesmo processo da Op√ß√£o 1)

### Checklist de Qualidade
- [ ] CSS corporativo aplicado (cores, cards, badges)
- [ ] Cache Streamlit configurado (`@st.cache_data`, `@st.cache_resource`)
- [ ] Paths relativos usando `Path(__file__).resolve().parents[N]`
- [ ] Dados sint√©ticos gerados com seed fixo (`random.seed(42)`)
- [ ] Modelos salvos em `models/*.pkl` com `joblib`
- [ ] Status badge correto no hub ("active" ou "dev")
- [ ] README espec√≠fico em `<subm√≥dulo>/README.md` (se aplic√°vel)

## Deploy no Streamlit Cloud

- **Entrypoint**: `streamlit_app.py` (definir no painel do Streamlit Cloud)
- **Python Version**: Especificado em [runtime.txt](../runtime.txt)
- **Recursos NLTK**: Rodar `analise-sentimentos/setup_nltk.py` no primeiro boot (adicionar ao script de inicializa√ß√£o se necess√°rio)
